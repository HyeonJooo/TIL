# ELK Stack

---
## ELK??
**ELK** = **E**lasticSearch + **L**ogStatsh + **K**ibana

---

## ElasticSearch
### 등장 배경
- 빅데이터 등장 -> 스키마가 다른 비정형 데이터 -> NoSQL 등장
- 이러한 데이터를 분석하기 위해 Hadoop같은 대용량 데이터 저장소 및 분석툴 사용
- ElasticSearch 역시 NoSQL

<br>

### 특징
- 분석 및 저장 기능
- Logstash를 통해 수신된 데이터를 저장소에 저장하는 역할
- 정형, 비정형, 위치정보 등 원하는 방법으로 다양한 유형의 검색을 수행
- RESTful API와 JSON 사용
- 거의 실시간 검색 플랫폼(Near Realtime)
- (분산환경)검색엔진이긴 하지만 동시에 데이터 적재를 위한 저장소로 활용 가능

<br>

### 주요 개념
 - ### Cluster<br>
하나 이상의 노드 모음<br>
기본적으로 'elasticsearch'라는 고유한 이름으로 식별

- ### Node<br>
데이터를 저장하고 클러스터의 인덱싱 및 검색 기능에 참여하는 단일 서버
노드에 할당되는 임의 UUID인 이름으로 식별

- ### Index<br>
유사한 특성을 갖는 문서들의 집합
단일 클러스터에서 원하는 만큼 인덱스를 정의할 수 있다.

- ### Type<br>
index 내에서 하나 이상의 type 정의 가능

- ### Document<br>
index를 생성할 수 있는 기본 정보 단위
JSON으로 표현

- ### Shards<br>
shards를 이용하여 index를 여러 조각으로 나눌 수 있다.
여러 노드에서 분산을 통해 작업을 분산 및 병렬 처리 할 수 있으므로 성능, 처리량이 향상됨.
---

## Logstash
### 특징
- 다양한 소스에서 동시에 데이터를 수집하고 변환
- 수집할 로그를 선정해서 지정된 서버(ElasticSearch)에 전송하는 역할
- 필터를 활용하여 데이터 정제

---

## Kibana
### 특징
- 데이터 시각화 도구
- 실시간으로 분석 가능
---

## Beats
- 서버에 에이전트로 설치하여 다양한 유형의 데이터를 Elastic 혹은 Logstash에 전송하는 역할<br>
- **FileBeat**, PacketBeat, MetricBeat, WinlogBeat

<br>

beats가 추가되어 **ELK + Beats**를 **ELK Stack**이라고 부른다.

---
## ELK Stack을 선택한 이유

### 내가 ELK를 활용한 부분
- 과제 중 API 호출의 성공 및 실패에 대한 통계 페이지를 구현해야 했음.


- API가 호출되고 종료될 때마다 로그가 남는다는 점을 이용해서 로그분석을 통해 데이터를 모으기로 함.


- 로그를 분석하는 방법을 찾던 중 ELK stack을 활용한 방법을 알게 됨.


<br>

- ELK라는 기술 자체도 중요하지만, 어떤 데이터를 가지고 어떤 목적을 위한 처리와 결과를 도출할 것인지가 중요하다.


- ElasticSearch를 데이터 저장소 역할로 활용하는 경우 전문(full-text) 검색이 가능하기 때문에 **적재된 데이터 안에서 원하는 정보를 찾는 방법이 매우 쉽고 빨라질 수 있다.**


- REST API를 통해서 데이터에 대한 접근이 가능하기 때문에 향후 **추가적인 기능구현이나 확장성에도 유리**하다.

<br>

발생하는 로그를 Filebeats를 통해 손쉽게 감지할 수 있고, Logstash를 통해 내 입맛에 맞게 정제하여 ElasticSearch에서 보관할 수 있다.
배치를 통해서 정제된 로그를 불러와 DB에 저장만 하면 심플하게 API 호출의 성공 및 실패 통계를 낼 수 있다.<br>

또한, 지금은 단순히 성공 및 실패에 대한 통계만 구현하지만 추후 어떤 API인지, IP는 어디인지, URL 경로는 어디인지 등 확장하기에도 유리하기 때문에 ELK Stack을 활용하기로 결정
